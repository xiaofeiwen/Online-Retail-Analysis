{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training logistic regression...\n",
      "training lightGBM...\n",
      "training random forest..\n",
      "training XGBoost...\n",
      "validation score is 0.2208267262912792\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df = pd.read_pickle('../data/train_transformed.p')\n",
    "order_products_compact = pd.read_hdf('../data/online_retail.h5','order_products_compact')\n",
    "\n",
    "def f1_score(l_true,l_pred):\n",
    "    tp = set(l_true).intersection(set(l_pred))\n",
    "    if not len(tp):\n",
    "        return 0\n",
    "    fp = set(l_pred).difference(tp)\n",
    "    fn = set(l_true).difference(tp)\n",
    "    p = len(tp) / (len(tp) + len(fp))\n",
    "    r = len(tp) / (len(tp) + len(fn))\n",
    "    f1 = 2 * (p * r) / (p + r)\n",
    "    return f1\n",
    "def avg_f1_score(df,pred,order_products_compact=order_products_compact,thres=0.09):\n",
    "    df_pred = pd.DataFrame({'order_id':df.order_id,'pred':pred,'product_id':df.product_id,\n",
    "                            'prior_size_max':df.user_order_size_max,\n",
    "                            'prior_size_mean':df.user_order_size_mean,\n",
    "                            'prior_size_std':df.user_order_size_std})\\\n",
    "                .sort_values(['order_id','pred'],ascending = [True,False]).reset_index(drop=True)\n",
    "    df_pred['pred_rank'] = df_pred.groupby('order_id').cumcount()\n",
    "    df_pred['prior_size_2std'] = df_pred.prior_size_mean + df_pred.prior_size_std * 2\n",
    "    df_pred = df_pred[df_pred.pred_rank < df_pred.prior_size_max]\\\n",
    "            .reset_index(drop=True)\n",
    "    d = {}\n",
    "    for row in df_pred.itertuples():\n",
    "        order_id = row.order_id\n",
    "        if row.pred_rank == 0 or row.pred > thres:\n",
    "            try:\n",
    "                d[order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                d[order_id] = str(row.product_id)\n",
    "    df_pred_compact = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "    df_pred_compact.reset_index(inplace=True)\n",
    "    df_pred_compact.columns = ['order_id', 'y_pred']\n",
    "    df_pred_compact['y_pred'] = df_pred_compact['y_pred'].str.split()\n",
    "    df_pred_compact = df_pred_compact.merge(order_products_compact[['order_id','product_id']],how='left',\n",
    "                                                       on='order_id')\n",
    "    scores = []\n",
    "    for row in df_pred_compact.itertuples():\n",
    "        y_pred = row.y_pred\n",
    "        y_true = row.product_id\n",
    "        score = f1_score(y_true,y_pred)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "f_to_use_tree = ['user_total_orders',\n",
    "       'user_total_items', 'user_total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_order_size_mean','user_order_size_max','user_order_size_std',\n",
    "       'user_total_item_quantity', 'user_total_spent',\n",
    "       'user_sum_days_between_orders', 'user_reorder_ratio',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'product_reorder_rate',\n",
    "       'product_total_quantity_sold', 'product_avg_price', 'prod_first_buy',\n",
    "       'prod_1reorder_ratio',\n",
    "       'UP_orders', 'UP_orders_ratio', 'UP_total_quantity',\n",
    "       'UP_order_rate_since_first_order']\n",
    "f_to_use_lgr = ['user_total_orders', 'user_average_days_between_orders', 'user_order_size_mean', \n",
    "             'user_total_item_quantity', 'order_hour_of_day','order_dow', 'days_since_ratio',\n",
    "             'product_orders', 'product_avg_price', \n",
    "             'UP_orders', 'UP_total_quantity', \n",
    "             'user_sum_days_between_orders','user_reorder_ratio','prod_1reorder_ratio']\n",
    "\n",
    "# train / val split\n",
    "np.random.seed(42)\n",
    "unique_users = df.user_id.unique()\n",
    "np.random.shuffle(unique_users)\n",
    "sp = int(len(unique_users)*0.8)\n",
    "train_users = unique_users[:sp]\n",
    "val_users = unique_users[sp:]\n",
    "df_train = df[df.user_id.isin(train_users)]\n",
    "df_val = df[df.user_id.isin(val_users)]\n",
    "\n",
    "# logistic regression\n",
    "print ('training logistic regression...')\n",
    "lgr = LogisticRegression(random_state=42,n_jobs=-1,C=100).fit(df_train[f_to_use_lgr],df_train['labels'].values)\n",
    "val_pred_lgr = lgr.predict_proba(df_val[f_to_use_lgr])[:,1]\n",
    "\n",
    "# LightGBM\n",
    "print ('training lightGBM...')\n",
    "d_train = lgb.Dataset(df_train[f_to_use_tree],label=df_train['labels'].values)\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 128,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5,\n",
    "    'learning_rate': 0.053,\n",
    "}\n",
    "bst = lgb.train(params, d_train, 100)\n",
    "val_pred_lgb = bst.predict(df_val[f_to_use_tree])\n",
    "\n",
    "# random forest\n",
    "print ('training random forest..')\n",
    "rfc = RandomForestClassifier(random_state = 42, n_estimators=100, max_depth = 7, n_jobs=-1,min_samples_split=100).\\\n",
    "        fit(df_train[f_to_use_tree],df_train['labels'].values)\n",
    "val_pred_rf = rfc.predict_proba(df_val[f_to_use_tree])[:,1]\n",
    "\n",
    "# XGBoost\n",
    "print ('training XGBoost...')\n",
    "d_train = xgb.DMatrix(df_train[f_to_use_tree],label=df_train['labels'].values)\n",
    "xgb_params = {\n",
    "    \"objective\"         : \"reg:logistic\"\n",
    "    ,\"eval_metric\"      : \"logloss\"\n",
    "    ,\"eta\"              : 0.15\n",
    "    ,\"max_depth\"        : 8\n",
    "    ,\"min_child_weight\" :10\n",
    "    ,\"gamma\"            :0.70\n",
    "    ,\"subsample\"        :0.76\n",
    "    ,\"colsample_bytree\" :0.95\n",
    "    ,\"alpha\"            :2e-05\n",
    "    ,\"lambda\"           :10\n",
    "}\n",
    "bst = xgb.train(params=xgb_params, dtrain=d_train, num_boost_round=100)\n",
    "val_pred_xgb = bst.predict(xgb.DMatrix(df_val[f_to_use_tree]))\n",
    "\n",
    "# Model combination\n",
    "val_pred = val_pred_lgb * 0.2 + val_pred_xgb * 0.5 + val_pred_rf * 0.1 + val_pred_lgr * 0.2\n",
    "score = avg_f1_score(df_val,val_pred)\n",
    "print ('validation score is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
